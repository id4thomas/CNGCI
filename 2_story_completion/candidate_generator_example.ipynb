{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import (\n",
    "\tAutoTokenizer, AutoModelForCausalLM\n",
    ")\n",
    "\n",
    "from src.modules.loader import (\n",
    "\tload_subject_extractor,\n",
    "\tload_commonsense_generator,\n",
    "\tload_nli_predictor\n",
    ")\n",
    "from src.modules.commonsense_relation_generator import CATEGORIES\n",
    "from src.candidate_generator import ObsLM245NextSentenceCandidateGenerator\n",
    "from src.story_dataclasses import CommonsenseRelation, StorySentence, ConflictStory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"weights/story_completion/roc_finetune_obs_lm_245_001\"\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "commonsense_generator = load_commonsense_generator(\n",
    "\tcomet_model_dir = \"weights/comet-atomic_2020_BART\",\n",
    "\tembedding_model_dir = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "\tdevice = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make Sample Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator_batch_size = 32\n",
    "text_embedder_batch_size = 128\n",
    "decode_params = {\n",
    "\t\"num_beams\": 5,\n",
    "\t\"num_return_sequences\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/yrsong_roc/lib/python3.8/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Initialize Sample Story\n",
    "context_sentence = StorySentence(\n",
    "\tidx = 0,\n",
    "\tvalue = \"Lana was trying to figure out how to play a song.\",\n",
    "\tcharacter = \"\",\n",
    "\tsentence_type = \"context\",\n",
    "\tcommonsense_relations = []\n",
    ")\n",
    "context_sentence.commonsense_relations = commonsense_generator.generate(\n",
    "\tcontext_sentence.value,\n",
    "\trelation_types = CATEGORIES,\n",
    "\tdecode_params = decode_params,\n",
    "\ttext_generator_batch_size = text_generator_batch_size,\n",
    "\ttext_embedder_batch_size = text_embedder_batch_size\n",
    ")\n",
    "\n",
    "obstacle_sentence = StorySentence(\n",
    "\tidx = 2,\n",
    "\tvalue = \"The song is very difficult.\",\n",
    "\tcharacter = \"\",\n",
    "\tsentence_type = \"obstacle\",\n",
    "\tcommonsense_relations = []\n",
    ")\n",
    "obstacle_sentence.commonsense_relations = commonsense_generator.generate(\n",
    "\tobstacle_sentence.value,\n",
    "\trelation_types = CATEGORIES,\n",
    "\tdecode_params = decode_params,\n",
    "\ttext_generator_batch_size = text_generator_batch_size,\n",
    "\ttext_embedder_batch_size = text_embedder_batch_size\n",
    ")\n",
    "\n",
    "## S2\n",
    "s2_sentence = StorySentence(\n",
    "\tidx = 1,\n",
    "\tvalue = \"For some reason, she couldn't figure out how to play the song.\",\n",
    "\tcharacter = \"\",\n",
    "\tsentence_type = \"other\",\n",
    "\tcommonsense_relations = []\n",
    ")\n",
    "s2_sentence.commonsense_relations = commonsense_generator.generate(\n",
    "\ts2_sentence.value,\n",
    "\trelation_types = CATEGORIES,\n",
    "\tdecode_params = decode_params,\n",
    "\ttext_generator_batch_size = text_generator_batch_size,\n",
    "\ttext_embedder_batch_size = text_embedder_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = ConflictStory(\n",
    "\tnum_sentences = 3,\n",
    "\tcontext_idx = 0,\n",
    "\tobstacle_idx = 2,\n",
    "\tsentences = {\n",
    "\t\t0: context_sentence,\n",
    "\t\t1: s2_sentence,\n",
    "\t\t2: obstacle_sentence\n",
    "\t}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test Candidate Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_dir)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ObsLM245NextSentenceCandidateGenerator(\n",
    "\tmodel = model,\n",
    "\ttokenizer = tokenizer,\n",
    "\tdevice = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = \"Lana was trying to figure out how to play a song.\"\n",
    "obstacles = \"The song is very difficult.\"\n",
    "# S2\n",
    "previous_sentences = [\"For some reason, she couldn't figure out how to play the song.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_params = {\n",
    "\t\"num_beams\": 20,\n",
    "\t\"num_beam_groups\": 5,\n",
    "\t# \"temperature\": 0.9,\n",
    "\t\"top_k\": 40,\n",
    "    \"num_return_sequences\": 5,\n",
    "\t\"repetition_penalty\": 10.0,\n",
    "    \"diversity_penalty\": 100.0,\n",
    "\t\"max_new_tokens\": 128,\n",
    "\t\"early_stopping\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['She asked her friend for help.',\n",
       " 'She asked her friend for help.',\n",
       " 'She asked her friend for help.',\n",
       " 'She asked her friend for help.',\n",
       " \"Lana's friends suggested that she try playing it for herself instead of someone else.\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.generate(story = story, decode_params = decode_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yrsong_roc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
