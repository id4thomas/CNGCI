{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "from src.modules.loader import (\n",
    "\tload_subject_extractor,\n",
    "\tload_commonsense_generator,\n",
    "\tload_nli_predictor\n",
    ")\n",
    "from src.modules.commonsense_relation_generator import CATEGORIES\n",
    "\n",
    "from src.scorer import ImplicationRuleScorer\n",
    "from src.story_dataclasses import CommonsenseRelation, StorySentence, ConflictStory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coref model loaded.\n"
     ]
    }
   ],
   "source": [
    "subject_extractor = load_subject_extractor(model = \"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "commonsense_generator = load_commonsense_generator(\n",
    "\tcomet_model_dir = \"weights/comet-atomic_2020_BART\",\n",
    "\tembedding_model_dir = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "\tdevice = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_predictor = load_nli_predictor(\n",
    "\tmodel_dir = \"cross-encoder/nli-distilroberta-base\",\n",
    "\tdevice = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make Sample Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator_batch_size = 32\n",
    "text_embedder_batch_size = 128\n",
    "decode_params = {\n",
    "\t\"num_beams\": 5,\n",
    "\t\"num_return_sequences\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/yrsong_roc/lib/python3.8/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Initialize Sample Story\n",
    "context_sentence = StorySentence(\n",
    "\tidx = 0,\n",
    "\tvalue = \"Lana was trying to figure out how to play a song.\",\n",
    "\tcharacter = \"\",\n",
    "\tsentence_type = \"context\",\n",
    "\tcommonsense_relations = []\n",
    ")\n",
    "context_sentence.commonsense_relations = commonsense_generator.generate(\n",
    "\tcontext_sentence.value,\n",
    "\trelation_types = CATEGORIES,\n",
    "\tdecode_params = decode_params,\n",
    "\ttext_generator_batch_size = text_generator_batch_size,\n",
    "\ttext_embedder_batch_size = text_embedder_batch_size\n",
    ")\n",
    "\n",
    "obstacle_sentence = StorySentence(\n",
    "\tidx = 2,\n",
    "\tvalue = \"The song is very difficult.\",\n",
    "\tcharacter = \"\",\n",
    "\tsentence_type = \"obstacle\",\n",
    "\tcommonsense_relations = []\n",
    ")\n",
    "obstacle_sentence.commonsense_relations = commonsense_generator.generate(\n",
    "\tobstacle_sentence.value,\n",
    "\trelation_types = CATEGORIES,\n",
    "\tdecode_params = decode_params,\n",
    "\ttext_generator_batch_size = text_generator_batch_size,\n",
    "\ttext_embedder_batch_size = text_embedder_batch_size\n",
    ")\n",
    "\n",
    "## S2\n",
    "s2_sentence = StorySentence(\n",
    "\tidx = 1,\n",
    "\tvalue = \"For some reason, she couldn't figure out how to play the song.\",\n",
    "\tcharacter = \"\",\n",
    "\tsentence_type = \"other\",\n",
    "\tcommonsense_relations = []\n",
    ")\n",
    "s2_sentence.commonsense_relations = commonsense_generator.generate(\n",
    "\ts2_sentence.value,\n",
    "\trelation_types = CATEGORIES,\n",
    "\tdecode_params = decode_params,\n",
    "\ttext_generator_batch_size = text_generator_batch_size,\n",
    "\ttext_embedder_batch_size = text_embedder_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## S4\n",
    "s4_candidate = StorySentence(\n",
    "\tidx = 3,\n",
    "\tvalue = \"Finally she decided to ask her friend for help.\",\n",
    "\tcharacter = \"\",\n",
    "\tsentence_type = \"other\",\n",
    "\tcommonsense_relations = []\n",
    ")\n",
    "s4_candidate.commonsense_relations = commonsense_generator.generate(\n",
    "\ts4_candidate.value,\n",
    "\trelation_types = CATEGORIES,\n",
    "\tdecode_params = decode_params,\n",
    "\ttext_generator_batch_size = text_generator_batch_size,\n",
    "\ttext_embedder_batch_size = text_embedder_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = ConflictStory(\n",
    "\tnum_sentences = 4,\n",
    "\tcontext_idx = 0,\n",
    "\tobstacle_idx = 2,\n",
    "\tsentences = {\n",
    "\t\t0: context_sentence,\n",
    "\t\t1: s2_sentence,\n",
    "\t\t2: obstacle_sentence,\n",
    "\t\t3: s4_candidate\n",
    "\t}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test ImplicationRuleScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_dir = \"rule_configs/comet_rule4.json\"\n",
    "with open(rule_dir, \"r\") as f:\n",
    "\trules = json.load(f)\n",
    "\n",
    "scorer = ImplicationRuleScorer(\n",
    "\tnli_rules = rules[\"implication\"],\n",
    "\tweight_rules = rules[\"weights\"],\n",
    "\tsubject_extractor = subject_extractor,\n",
    "\tnli_predictor = nli_predictor,\n",
    "\tnli_predictor_batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 129.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLI Predictor input 16\n",
      "NLI Predictor input 25\n",
      "NLI Predictor input 25\n",
      "NLI Score: 0.6667\n",
      "Weight: 0.3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21666666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "context:\n",
    "100%|██████████| 3/3 [00:00<00:00, 129.70it/s]\n",
    "NLI Predictor input 16\n",
    "NLI Predictor input 25\n",
    "NLI Predictor input 25\n",
    "NLI Score: 0.6667\n",
    "Weight: 0.3250\n",
    "-> 0.21666666666666667\n",
    "\n",
    "obstacle:\n",
    "100%|██████████| 4/4 [00:00<00:00, 145.55it/s]\n",
    "NLI Predictor input 20\n",
    "NLI Predictor input 25\n",
    "NLI Predictor input 20\n",
    "NLI Predictor input 20\n",
    "NLI Score: 0.2500\n",
    "Weight: 0.3875\n",
    "-> 0.096875\n",
    "\n",
    "preceding:\n",
    "100%|██████████| 2/2 [00:00<00:00, 182.81it/s]\n",
    "NLI Predictor input 20\n",
    "NLI Predictor input 20\n",
    "NLI Score: 0.5000\n",
    "Weight: 0.3000\n",
    "-> 0.15\n",
    "'''\n",
    "\n",
    "scorer.calculate_score(\n",
    "\tstory = story,\n",
    "\tcandidate_sentence_idx = 3,\n",
    "\tcomparing_sentence_type = \"context\",\n",
    "\t# comparing_sentence_type = \"obstacle\",\n",
    "\t# comparing_sentence_type = \"preceding\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
